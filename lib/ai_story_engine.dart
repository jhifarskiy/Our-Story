import 'dart:async';
import 'dart:convert';
import 'dart:io';

import 'package:http/http.dart' as http;

/// AI Story Engine using Ollama HTTP API for offline text generation
class AiStoryEngine {
  static final AiStoryEngine _instance = AiStoryEngine._internal();
  factory AiStoryEngine() => _instance;

  AiStoryEngine._internal();

  bool _isInitialized = false;
  String _model = "tinyllama"; // –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ Ollama
  final String _baseUrl = "http://127.0.0.1:11434/api";

  bool get isInitialized => _isInitialized;

  /// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Ollama (–ø—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ API –¥–æ—Å—Ç—É–ø–Ω–æ)
  Future<void> init({String model = "tinyllama"}) async {
    if (_isInitialized) return;

    _model = model;

    try {
      final response = await http
          .get(Uri.parse("$_baseUrl/tags"))
          .timeout(const Duration(seconds: 5));

      if (response.statusCode != 200) {
        throw Exception("‚ùå Ollama API not available: ${response.body}");
      }

      print("‚úÖ Ollama initialized. Available models:\n${response.body}");
      _isInitialized = true;
    } catch (e) {
      throw Exception("‚ö†Ô∏è Ollama API not responding: $e");
    }
  }

  /// –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (–ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –∑–∞ —Ä–∞–∑)
  Future<String> generateText(String prompt) async {
    if (!_isInitialized) {
      throw Exception("‚ö†Ô∏è Model not initialized. Call init() first.");
    }

    final response = await http.post(
      Uri.parse("$_baseUrl/generate"),
      headers: {"Content-Type": "application/json"},
      body: jsonEncode({"model": _model, "prompt": prompt, "stream": false}),
    );

    if (response.statusCode != 200) {
      throw Exception("‚ùå Ollama error: ${response.body}");
    }

    final data = jsonDecode(response.body);
    return data["response"]?.toString().trim() ?? "";
  }

  /// –ü–æ—Ç–æ–∫–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (–ø–æ —Ç–æ–∫–µ–Ω–∞–º/—á–∞–Ω–∫–∞–º)
  Stream<String> generateStream(String prompt) async* {
    if (!_isInitialized) {
      throw Exception("‚ö†Ô∏è Model not initialized. Call init() first.");
    }

    final request = http.Request("POST", Uri.parse("$_baseUrl/generate"))
      ..headers["Content-Type"] = "application/json"
      ..body = jsonEncode({"model": _model, "prompt": prompt, "stream": true});

    final client = http.Client();
    final response = await client.send(request);

    if (response.statusCode != 200) {
      final err = await response.stream.bytesToString();
      throw Exception("‚ùå Ollama stream error: $err");
    }

    final stream = response.stream
        .transform(utf8.decoder)
        .transform(const LineSplitter());

    await for (final line in stream) {
      if (line.trim().isEmpty) continue;
      try {
        final data = jsonDecode(line);
        if (data.containsKey("response")) {
          yield data["response"];
        }
      } catch (_) {
        // –µ—Å–ª–∏ –Ω–µ JSON ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
      }
    }

    client.close();
  }

  /// –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
  Future<void> dispose() async {
    _isInitialized = false;
    print("üßπ Engine disposed");
  }
}

/// –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
Future<void> main() async {
  final engine = AiStoryEngine();

  print("üöÄ Starting Ollama HTTP test...");

  try {
    await engine.init(model: "tinyllama");

    final response = await engine.generateText(
      "–ü—Ä–∏–¥—É–º–∞–π –∫–æ—Ä–æ—Ç–∫—É—é —Å–∫–∞–∑–∫—É –ø—Ä–æ –¥—Ä–∞–∫–æ–Ω–∞.",
    );
    print("LLM: $response");

    print("\n--- Stream test ---");
    await for (final token in engine.generateStream(
      "–ù–∞–ø–∏—à–∏ –¥–∏–∞–ª–æ–≥ —Ä—ã—Ü–∞—Ä—è –∏ –º–∞–≥–∞.",
    )) {
      stdout.write(token);
    }
  } finally {
    await engine.dispose();
  }
}
